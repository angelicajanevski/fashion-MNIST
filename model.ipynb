{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rp1DeXK0utBZ"
   },
   "outputs": [],
   "source": [
    "# set to True if running in Google Colaboratory else False\n",
    "colab = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "O3hQH-W9R2-L",
    "outputId": "fe4e68ff-282c-4751-a899-d29c0bfaf3d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow 2.x selected.\n"
     ]
    }
   ],
   "source": [
    "### import packages\n",
    "if colab:\n",
    "    try:\n",
    "        # %tensorflow_version only exists in Colab.\n",
    "        %tensorflow_version 2.x\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Flatten, Dense, MaxPooling2D, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "colab_type": "code",
    "id": "UamqrKHrvZqf",
    "outputId": "a8a1f585-21ba-4da1-a397-d925cd76248f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'fashion-MNIST'...\n",
      "remote: Enumerating objects: 11, done.\u001b[K\n",
      "remote: Counting objects: 100% (11/11), done.\u001b[K\n",
      "remote: Compressing objects: 100% (9/9), done.\u001b[K\n",
      "remote: Total 14 (delta 2), reused 11 (delta 2), pack-reused 3\u001b[K\n",
      "Unpacking objects: 100% (14/14), done.\n",
      "/content/fashion-MNIST\n",
      "Archive:  data.zip\n",
      "   creating: data/\n",
      "  inflating: data/train_labels.csv   \n",
      "   creating: __MACOSX/\n",
      "   creating: __MACOSX/data/\n",
      "  inflating: __MACOSX/data/._train_labels.csv  \n",
      "  inflating: data/label_int_to_str_mapping.csv  \n",
      "  inflating: __MACOSX/data/._label_int_to_str_mapping.csv  \n",
      "  inflating: data/train_images.npy   \n",
      "  inflating: __MACOSX/data/._train_images.npy  \n",
      "  inflating: data/test_images.npy    \n",
      "  inflating: __MACOSX/data/._test_images.npy  \n",
      "  inflating: __MACOSX/._data         \n"
     ]
    }
   ],
   "source": [
    "### clone GitHub repository and unzip data if running in Google Colab\n",
    "if colab:\n",
    "    !git clone https://github.com/atotschnig/fashion-MNIST.git\n",
    "    %cd fashion-MNIST/\n",
    "    !unzip data.zip\n",
    "    !rm -rf __MACOSX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3CPCI5MKunyU"
   },
   "outputs": [],
   "source": [
    "# set path variables\n",
    "path_data = 'data'\n",
    "path_submission = 'submissions'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1wxrE4Y1hea7"
   },
   "outputs": [],
   "source": [
    "### helper functions\n",
    "def process_images(X, augment=False):\n",
    "\n",
    "    # normalize image data\n",
    "    X = X / 255\n",
    "\n",
    "    # reshape into (n_samples, width, height, 1)\n",
    "    X = X.reshape(X.shape + (1,))\n",
    "\n",
    "    if augment:\n",
    "        # vertical reflection to augment data set\n",
    "        X_vertical = np.flip(X,2)\n",
    "        X = np.concatenate((X, X_vertical), 0)\n",
    "    return X\n",
    "\n",
    "def process_labels(y, augment=False):\n",
    "    \n",
    "    # drop 'ID' column\n",
    "    if augment:\n",
    "        return  np.concatenate((y[:,1], y[:,1]), 0) \n",
    "\n",
    "    else:\n",
    "        return y[:,1]\n",
    "\n",
    "def predict(X, model):\n",
    "    y = model.predict(X)\n",
    "    return np.argmax(y, axis=1)\n",
    "\n",
    "def categorical_to_label(y):\n",
    "    return np.argmax(y, axis=1)\n",
    "\n",
    "def get_acc(X, y, model):\n",
    "    preds = predict(X, model)\n",
    "    # acc = np.mean(preds==categorical_to_label(y))\n",
    "    acc = np.mean(preds==y)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zd6M1IwFUVxf"
   },
   "outputs": [],
   "source": [
    "def get_model_1():\n",
    "    \"\"\"model architecture based on Kaggle kernel https://www.kaggle.com/bugraokcu/cnn-with-keras\"\"\"\n",
    "\n",
    "    model = Sequential([\n",
    "        Conv2D(filters=32, kernel_size=3, activation='relu', kernel_initializer='he_normal', input_shape=im_shape),\n",
    "        MaxPooling2D(2,2),\n",
    "        Dropout(0.25),\n",
    "        Conv2D(filters=64, kernel_size=3, activation='relu'),\n",
    "        MaxPooling2D(2,2),\n",
    "        Dropout(0.25),\n",
    "        Conv2D(filters=128, kernel_size=3, activation='relu'),\n",
    "        Dropout(0.4),\n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        Dense(10, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer=Adam(),\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "  \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NbSoVr2NiLI_"
   },
   "outputs": [],
   "source": [
    "def get_model_2():\n",
    "    \"\"\"madel architecture based on Kaggle kernel https://www.kaggle.com/fuzzywizard/fashion-mnist-cnn-keras-accuracy-93\"\"\"\n",
    "\n",
    "    model = Sequential([\n",
    "        Conv2D(filters=32, kernel_size=3, activation='relu', kernel_initializer='he_normal', input_shape=im_shape),\n",
    "        BatchNormalization(),\n",
    "        Conv2D(filters=32, kernel_size=3, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.25),\n",
    "        Conv2D(filters=64, kernel_size=3, activation='relu'),\n",
    "        MaxPooling2D(2,2),\n",
    "        Dropout(0.25),\n",
    "        Conv2D(filters=128, kernel_size=3, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.25),\n",
    "        Flatten(),\n",
    "        Dense(512, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "        Dense(128, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "        Dense(10, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer=Adam(),\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "  \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6PS9sDJT5Yn1"
   },
   "outputs": [],
   "source": [
    "def get_model_3():\n",
    "    \"\"\"modified version of model 2\"\"\"\n",
    "\n",
    "    model = Sequential([\n",
    "        Conv2D(filters=32, kernel_size=3, activation='relu', kernel_initializer='he_normal', input_shape=im_shape),\n",
    "        BatchNormalization(),\n",
    "        Conv2D(filters=32, kernel_size=3, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(2,2),\n",
    "        Dropout(0.25),\n",
    "        Conv2D(filters=64, kernel_size=3, activation='relu'),\n",
    "        MaxPooling2D(2,2),\n",
    "        Dropout(0.25),\n",
    "        Conv2D(filters=128, kernel_size=3, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(2,2),\n",
    "        Dropout(0.25),\n",
    "        Flatten(),\n",
    "        Dense(512, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "        Dense(128, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "        Dense(10, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer=Adam(),\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "  \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dhq5uWjcbTAA"
   },
   "outputs": [],
   "source": [
    "### code for k-fold cross-validation (not used)\n",
    "\n",
    "# epochs = 25\n",
    "# batch_size = 256\n",
    "# n_splits=10\n",
    "\n",
    "# # load images and labels\n",
    "# X = np.load('train_images.npy')\n",
    "# y = np.loadtxt('train_labels.csv', delimiter=',', skiprows=1)\n",
    "\n",
    "# # process data\n",
    "# X = process_images(X)\n",
    "# y = process_labels(y)\n",
    "\n",
    "# # get image shape\n",
    "# im_shape = X.shape[1:]\n",
    "\n",
    "# kfold = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=3791)\n",
    "\n",
    "# acc = []\n",
    "# val_acc = []\n",
    "\n",
    "# for train, val in kfold.split(X, y):\n",
    "\n",
    "#   model = get_model()\n",
    "#   model.fit(X[train], y[train], epochs=epochs, batch_size=batch_size, validation_data=(X[val], y[val]))\n",
    "\n",
    "#   acc.append(get_acc(X[train], y[train], model))\n",
    "#   val_acc.append(get_acc(X[val], y[val], model))\n",
    "\n",
    "# print('Mean training accuracy:', np.mean(acc))\n",
    "# print('Mean validation accuracy:', np.mean(val_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 918
    },
    "colab_type": "code",
    "id": "AEGY5U6eW4yR",
    "outputId": "e15d314b-c136-4e72-a071-0384090ec4bb",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 90000 samples, validate on 10000 samples\n",
      "Epoch 1/25\n",
      "90000/90000 [==============================] - 53s 589us/sample - loss: 0.6672 - accuracy: 0.7615 - val_loss: 0.4379 - val_accuracy: 0.8345\n",
      "Epoch 2/25\n",
      "90000/90000 [==============================] - 47s 526us/sample - loss: 0.4694 - accuracy: 0.8308 - val_loss: 0.4196 - val_accuracy: 0.8496\n",
      "Epoch 3/25\n",
      "90000/90000 [==============================] - 47s 527us/sample - loss: 0.4184 - accuracy: 0.8504 - val_loss: 0.3512 - val_accuracy: 0.8642\n",
      "Epoch 4/25\n",
      "90000/90000 [==============================] - 48s 528us/sample - loss: 0.3789 - accuracy: 0.8627 - val_loss: 0.3151 - val_accuracy: 0.8816\n",
      "Epoch 5/25\n",
      "90000/90000 [==============================] - 48s 528us/sample - loss: 0.3554 - accuracy: 0.8713 - val_loss: 0.3023 - val_accuracy: 0.8856\n",
      "Epoch 6/25\n",
      "90000/90000 [==============================] - 48s 532us/sample - loss: 0.3322 - accuracy: 0.8803 - val_loss: 0.2836 - val_accuracy: 0.8948\n",
      "Epoch 7/25\n",
      "90000/90000 [==============================] - 48s 528us/sample - loss: 0.3202 - accuracy: 0.8836 - val_loss: 0.2993 - val_accuracy: 0.8911\n",
      "Epoch 8/25\n",
      "90000/90000 [==============================] - 47s 527us/sample - loss: 0.3012 - accuracy: 0.8906 - val_loss: 0.2954 - val_accuracy: 0.8952\n",
      "Epoch 9/25\n",
      "90000/90000 [==============================] - 48s 528us/sample - loss: 0.2883 - accuracy: 0.8944 - val_loss: 0.2965 - val_accuracy: 0.8895\n",
      "Epoch 10/25\n",
      "90000/90000 [==============================] - 47s 528us/sample - loss: 0.2775 - accuracy: 0.8998 - val_loss: 0.2783 - val_accuracy: 0.8982\n",
      "Epoch 11/25\n",
      "90000/90000 [==============================] - 47s 527us/sample - loss: 0.2669 - accuracy: 0.9029 - val_loss: 0.2889 - val_accuracy: 0.8923\n",
      "Epoch 12/25\n",
      "90000/90000 [==============================] - 48s 532us/sample - loss: 0.2550 - accuracy: 0.9063 - val_loss: 0.3249 - val_accuracy: 0.8758\n",
      "Epoch 13/25\n",
      "90000/90000 [==============================] - 48s 528us/sample - loss: 0.2494 - accuracy: 0.9093 - val_loss: 0.2619 - val_accuracy: 0.9006\n",
      "Epoch 14/25\n",
      "90000/90000 [==============================] - 48s 531us/sample - loss: 0.2363 - accuracy: 0.9124 - val_loss: 0.2584 - val_accuracy: 0.9048\n",
      "Epoch 15/25\n",
      "90000/90000 [==============================] - 47s 528us/sample - loss: 0.2294 - accuracy: 0.9154 - val_loss: 0.2631 - val_accuracy: 0.9055\n",
      "Epoch 16/25\n",
      "90000/90000 [==============================] - 47s 526us/sample - loss: 0.2262 - accuracy: 0.9180 - val_loss: 0.2590 - val_accuracy: 0.9058\n",
      "Epoch 17/25\n",
      "90000/90000 [==============================] - 49s 548us/sample - loss: 0.2168 - accuracy: 0.9209 - val_loss: 0.2633 - val_accuracy: 0.9070\n",
      "Epoch 18/25\n",
      "90000/90000 [==============================] - 49s 545us/sample - loss: 0.2097 - accuracy: 0.9226 - val_loss: 0.2597 - val_accuracy: 0.9085\n",
      "Epoch 19/25\n",
      "90000/90000 [==============================] - 50s 551us/sample - loss: 0.2020 - accuracy: 0.9271 - val_loss: 0.2614 - val_accuracy: 0.9091\n",
      "Epoch 20/25\n",
      "90000/90000 [==============================] - 48s 530us/sample - loss: 0.2021 - accuracy: 0.9256 - val_loss: 0.2577 - val_accuracy: 0.9077\n",
      "Epoch 21/25\n",
      "90000/90000 [==============================] - 48s 531us/sample - loss: 0.1963 - accuracy: 0.9287 - val_loss: 0.2599 - val_accuracy: 0.9080\n",
      "Epoch 22/25\n",
      "90000/90000 [==============================] - 48s 531us/sample - loss: 0.1926 - accuracy: 0.9297 - val_loss: 0.2665 - val_accuracy: 0.9083\n",
      "Epoch 23/25\n",
      "90000/90000 [==============================] - 48s 530us/sample - loss: 0.1852 - accuracy: 0.9323 - val_loss: 0.2665 - val_accuracy: 0.9100\n",
      "Epoch 24/25\n",
      "90000/90000 [==============================] - 48s 530us/sample - loss: 0.1781 - accuracy: 0.9343 - val_loss: 0.2706 - val_accuracy: 0.9083\n",
      "Epoch 25/25\n",
      "90000/90000 [==============================] - 48s 535us/sample - loss: 0.1755 - accuracy: 0.9354 - val_loss: 0.2669 - val_accuracy: 0.9110\n",
      "Training accuracy: 0.9730111111111112\n",
      "Validation accuracy: 0.911\n"
     ]
    }
   ],
   "source": [
    "### train model\n",
    "\n",
    "models = {1:get_model_1, 2:get_model_2, 3:get_model_3}\n",
    "\n",
    "# hyperparameters for final model\n",
    "model_id = 2\n",
    "augment = True\n",
    "epochs = 25\n",
    "batch_size = 32\n",
    "\n",
    "# load images and labels\n",
    "X_train = np.load(os.path.join(path_data, 'train_images.npy'))\n",
    "y_train = np.loadtxt(os.path.join(path_data, 'train_labels.csv'), delimiter=',', skiprows=1)\n",
    "\n",
    "# process data\n",
    "X_train = process_images(X_train, augment=augment)\n",
    "y_train = process_labels(y_train, augment=augment)\n",
    "\n",
    "# get image shape\n",
    "im_shape = X_train.shape[1:]\n",
    "\n",
    "# train-validation split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=3791)\n",
    "\n",
    "# model = get_model_1()\n",
    "model = models[model_id]()\n",
    "history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_val,y_val))\n",
    "print('Training accuracy:', get_acc(X_train, y_train, model))\n",
    "print('Validation accuracy:', get_acc(X_val, y_val, model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A7JTJZkmhIjM"
   },
   "outputs": [],
   "source": [
    "### create submission.csv file\n",
    "\n",
    "# test model\n",
    "X_test = np.load(os.path.join(path_data, 'test_images.npy')).squeeze()\n",
    "y_test = predict(process_images(X_test), model)\n",
    "\n",
    "# save predictions\n",
    "df_test = pd.read_csv(os.path.join(path_submission, 'sample_submission.csv'))\n",
    "df_test['label'] = y_test\n",
    "df_test.to_csv(os.path.join(path_submission, 'submission.csv'), index=False)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "model.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
